# ===========================================================================
# GIFT-Eval Benchmark Configuration
# ===========================================================================
# GIFT-Eval (General Time Series Forecasting Model Evaluation)
# Comprehensive benchmark from Salesforce AI Research.
#
# Paper: arXiv:2410.10393
# Leaderboard: https://huggingface.co/spaces/Salesforce/GiftEval
#
# Protocol:
#   - 23 base datasets, ~98 task configurations
#   - TEST_SPLIT = 0.1 (last 10% of each series)
#   - Non-overlapping rolling windows (MAX_WINDOW = 20)
#   - Quantiles: {0.1, 0.2, ..., 0.9}
#
# Metrics: CRPS, MASE, WQL, sMAPE (11 metrics per configuration)
# Aggregation: Average rank / normalized scores
#
# Expected time: ~2 hr (A100 GPU)
#
# NOTE: This benchmark uses the gift-eval library adapter, not the
# standard Chronos-style YAML evaluator. The config below documents
# available datasets for reference and CLI integration.
#
# Local data: /group-volume/ts-dataset/benchmarks/gift_eval/
# Requires: pip install gift-eval
#
# Usage:
#   python run_benchmark.py \
#       --model-path /path/to/model \
#       --benchmarks gift_eval \
#       --gift-eval-data /group-volume/ts-dataset/benchmarks/gift_eval/
# ===========================================================================

# Available datasets (30 directories):
datasets_root: /group-volume/ts-dataset/benchmarks/gift_eval/

datasets:
  - LOOP_SEATTLE
  - M_DENSE
  - SZ_TAXI
  - bitbrains_fast_storage
  - bitbrains_rnd
  - bizitobs_application
  - bizitobs_l2c
  - bizitobs_service
  - car_parts_with_missing
  - covid_deaths
  - electricity
  - ett1
  - ett2
  - hierarchical_sales
  - hospital
  - jena_weather
  - kdd_cup_2018_with_missing
  - m4_daily
  - m4_hourly
  - m4_monthly
  - m4_quarterly
  - m4_weekly
  - m4_yearly
  - restaurant
  - saugeenday
  - solar
  - temperature_rain_with_missing
  - us_births

terms:
  - short
  - medium
  - long
